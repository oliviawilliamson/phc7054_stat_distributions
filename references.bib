@article{knuth84,
  author = {Knuth, Donald E.},
  title = {Literate Programming},
  year = {1984},
  issue_date = {May 1984},
  publisher = {Oxford University Press, Inc.},
  address = {USA},
  volume = {27},
  number = {2},
  issn = {0010-4620},
  url = {https://doi.org/10.1093/comjnl/27.2.97},
  doi = {10.1093/comjnl/27.2.97},
  journal = {Comput. J.},
  month = may,
  pages = {97–111},
  numpages = {15}
}
@misc{cdc2022,
  title        = {COVID-19 Vaccination Coverage, United States, 2022},
  author       = {{Centers for Disease Control and Prevention}},
  year         = {2022},
  url          = {https://www.cdc.gov/vaccines/imz-managers/coverage/index.html},
  note         = {Accessed: 2025-09-15}
}

@article{hamzaBinomialDistributionMetaanalysis2008,
  title = {The Binomial Distribution of Meta-Analysis Was Preferred to Model within-Study Variability},
  author = {Hamza, Taye H. and {van Houwelingen}, Hans C. and Stijnen, Theo},
  year = {2008},
  month = jan,
  journal = {Journal of Clinical Epidemiology},
  volume = {61},
  number = {1},
  pages = {41--51},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2007.03.016},
  abstract = {OBJECTIVE: When studies report proportions such as sensitivity or specificity, it is customary to meta-analyze them using the DerSimonian and Laird random effects model. This method approximates the within-study variability of the proportion by a normal distribution, which may lead to bias for several reasons. Alternatively an exact likelihood approach based on the binomial within-study distribution can be used. This method can easily be performed in standard statistical packages. We investigate the performance of the standard method and the alternative approach. STUDY DESIGN AND SETTING: We compare the two approaches through a simulation study, in terms of bias, mean-squared error, and coverage probabilities. We varied the size of the overall sensitivity or specificity, the between-studies variance, the within-study sample sizes, and the number of studies. The methods are illustrated using a published meta-analysis data set. RESULTS: The exact likelihood approach performs always better than the approximate approach and gives unbiased estimates. The coverage probability, in particular for the profile likelihood, is also reasonably acceptable. In contrast, the approximate approach gives huge bias with very poor coverage probability in many cases. CONCLUSION: The exact likelihood approach is the method of preference and should be used whenever feasible.},
  langid = {english},
  pmid = {18083461},
  keywords = {Alzheimer Disease,Binomial Distribution,Data Interpretation Statistical,Diagnostic Techniques and Procedures,Fluorodeoxyglucose F18,Humans,Meta-Analysis as Topic,Models Statistical,Positron-Emission Tomography,Radiopharmaceuticals}
}

@article{nyagaMetapropStataCommand2014,
  title = {Metaprop: A {{Stata}} Command to Perform Meta-Analysis of Binomial Data},
  shorttitle = {Metaprop},
  author = {Nyaga, Victoria N. and Arbyn, Marc and Aerts, Marc},
  year = {2014},
  month = nov,
  journal = {Archives of Public Health},
  volume = {72},
  number = {1},
  pages = {39},
  issn = {2049-3258},
  doi = {10.1186/2049-3258-72-39},
  urldate = {2025-09-20},
  abstract = {Meta-analyses have become an essential tool in synthesizing evidence on clinical and epidemiological questions derived from a multitude of similar studies assessing the particular issue. Appropriate and accessible statistical software is needed to produce the summary statistic of interest.},
  keywords = {Binomial,Confidence intervals,Freeman-Tukey double arcsine transformation,Logistic-normal,Meta-analysis,Stata}
}

@article{snipenMicrobialComparativePangenomics2009,
  title = {Microbial Comparative Pan-Genomics Using Binomial Mixture Models},
  author = {Snipen, Lars and Alm{\o}y, Trygve and Ussery, David W.},
  year = {2009},
  month = aug,
  journal = {BMC Genomics},
  volume = {10},
  number = {1},
  pages = {385},
  issn = {1471-2164},
  doi = {10.1186/1471-2164-10-385},
  urldate = {2025-09-20},
  abstract = {The size of the core- and pan-genome of bacterial species is a topic of increasing interest due to the growing number of sequenced prokaryote genomes, many from the same species. Attempts to estimate these quantities have been made, using regression methods or mixture models. We extend the latter approach by using statistical ideas developed for capture-recapture problems in ecology and epidemiology.},
  keywords = {Coxiella Burnetii,Detection Probability,Francisella Tularensis,Gene Family,Mixture Model}
}

@article{spartaBinomialModelsUncover2024,
  title = {Binomial Models Uncover Biological Variation during Feature Selection of Droplet-Based Single-Cell {{RNA}} Sequencing},
  author = {Sparta, Breanne and Hamilton, Timothy and Natesan, Gunalan and Aragones, Samuel D. and Deeds, Eric J.},
  year = {2024},
  month = sep,
  journal = {PLoS computational biology},
  volume = {20},
  number = {9},
  pages = {e1012386},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1012386},
  abstract = {Effective analysis of single-cell RNA sequencing (scRNA-seq) data requires a rigorous distinction between technical noise and biological variation. In this work, we propose a simple feature selection model, termed "Differentially Distributed Genes" or DDGs, where a binomial sampling process for each mRNA species produces a null model of technical variation. Using scRNA-seq data where cell identities have been established a priori, we find that the DDG model of biological variation outperforms existing methods. We demonstrate that DDGs distinguish a validated set of real biologically varying genes, minimize neighborhood distortion, and enable accurate partitioning of cells into their established cell-type groups.},
  langid = {english},
  pmcid = {PMC11410258},
  pmid = {39241106},
  keywords = {Algorithms,Animals,Computational Biology,Gene Expression Profiling,Humans,Models Statistical,RNA Messenger,Sequence Analysis RNA,Single-Cell Analysis}
}

@article{young-xuPoolingOverdispersedBinomial2008,
  title = {Pooling Overdispersed Binomial Data to Estimate Event Rate},
  author = {{Young-Xu}, Yinong and Chan, K. Arnold},
  year = {2008},
  month = aug,
  journal = {BMC Medical Research Methodology},
  volume = {8},
  number = {1},
  pages = {58},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-8-58},
  urldate = {2025-09-20},
  abstract = {The beta-binomial model is one of the methods that can be used to validly combine event rates from overdispersed binomial data. Our objective is to provide a full description of this method and to update and broaden its applications in clinical and public health research.},
  langid = {english},
  keywords = {Dermatophytosis,Griseofulvin,Itraconazole,Terbinafine,Tinea Pedis}
}


@article{xue_regression_1997,
	title = {Regression analysis of discrete time survival data under heterogeneity},
	volume = {16},
	copyright = {Copyright © 1997 John Wiley \& Sons, Ltd.},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0258%2819970915%2916%3A17%3C1983%3A%3AAID-SIM628%3E3.0.CO%3B2-3},
	doi = {10.1002/(SICI)1097-0258(19970915)16:17<1983::AID-SIM628>3.0.CO;2-3},
	abstract = {This paper concerns the regression analysis of discrete time survival data for heterogeneous populations by means of frailty models. We express the survival time for each individual as a sequence of binary variables that indicate if the individual survived at each time point. The main result is that the likelihood for these indicators can be factored into contributions that involve the conditional survival probabilities integrated over the frailty distribution of the risk set (population-averaged). We then model these population-averaged conditional probabilities as a function of covariates. The result justifies the practice of treating the failure indicators as independent Bernoulli trials and fitting binary regression models for the conditional failure probabilities at each time point. However, we must interpret the regression coefficients as population-averaged rather than subject-specific parameters. We apply the method to the Framingham Heart Study on risk factors for cardiovascular disease. © 1997 by John Wiley \& Sons, Ltd.},
	language = {en},
	number = {17},
	urldate = {2025-09-11},
	journal = {Statistics in Medicine},
	author = {Xue, Xiaonan and Brookmeyer, Ron},
	year = {1997},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291097-0258\%2819970915\%2916\%3A17\%3C1983\%3A\%3AAID-SIM628\%3E3.0.CO\%3B2-3},
	pages = {1983--1993},
}

@inproceedings{bemando_machine-learning-based_2021,
	title = {Machine-{Learning}-{Based} {Prediction} {Models} of {Coronary} {Heart} {Disease} {Using} {Naïve} {Bayes} and {Random} {Forest} {Algorithms}},
	url = {https://ieeexplore.ieee.org/abstract/document/9537060},
	doi = {10.1109/ICSECS52883.2021.00049},
	abstract = {Coronary heart disease (CHD), alternatively known as cardiovascular disease (CVD) is the number one cause of death in the world. Accordingly, a plethora of research have been conducted to predict the early diagnosis of the heart disease and determine the most important risk factors associated with the disease. Despite these considerable efforts, the accuracy of the prediction has remained inadequate and the most important risk factors have remained elusive. This research paper discusses many risk factors associated with the disease and presents the prediction models of coronary heart disease using supervised machine learning algorithms, namely Gaussian Naïve Bayes, Bernoulli Naïve Bayes and Random Forest algorithms. It uses the public dataset from the Cleveland database of UCI repository of coronary heart disease patients. The results show that the Gaussian Naïve Bayes, Bernoulli Naïve Bayes and Random Forest algorithms have accuracies of 85.00\%, 85.00\% and 75.00\%, respectively. Moreover, the precision, F-measure and recall of the Gaussian and Bernoulli Naïve Bayes are higher than those of Random Forest algorithm, signifying its importance in predicting the early diagnosis of the disease.},
	urldate = {2025-09-11},
	booktitle = {2021 {International} {Conference} on {Software} {Engineering} \& {Computer} {Systems} and 4th {International} {Conference} on {Computational} {Science} and {Information} {Management} ({ICSECS}-{ICOCSIM})},
	author = {Bemando, Charles and Miranda, Eka and Aryuni, Mediana},
	month = aug,
	year = {2021},
	keywords = {Bernoulli Naïve Bayes, Computational modeling, Databases, factors, Gaussian Naïve Bayes, Heart, heart disease, machine learning, Machine learning algorithms, Prediction algorithms, Predictive models, Random Forest, risk, Scientific computing},
	pages = {232--237},
}

@misc{thompson_minimum_2010,
	title = {Minimum {Variance} {Estimators}},
	url = {https://faculty.washington.edu/eathomp/S341_10/Hwks/Cramer_Rao_soln.pdf},
	urldate = {2025-09-14},
	author = {Thompson, E.A.},
	month = feb,
	year = {2010},
}

@book{mccullagh_generalized_2018,
	address = {Boca Raton},
	title = {Generalized {Linear} {Models}},
	isbn = {978-0-412-31760-6},
	abstract = {The success of the first edition of Generalized Linear Models led to the updated Second Edition, which continues to provide a definitive unified, treatment of methods for the analysis of diverse types of data. Today, it remains popular for its clarity, richness of content and direct relevance to agricultural, biological, health, engineering, and other applications.The authors focus on examining the way a response variable depends on a combination of explanatory variables, treatment, and classification variables. They give particular emphasis to the important case where the dependence occurs through some unknown, linear combination of the explanatory variables.The Second Edition includes topics added to the core of the first edition, including conditional and marginal likelihood methods, estimating equations, and models for dispersion effects and components of dispersion. The discussion of other topics-log-linear and related models, log odds-ratio regression models, multinomial response models, inverse linear and related models, quasi-likelihood functions, and model checking-was expanded and incorporates significant revisions.Comprehension of the material requires simply a knowledge of matrix theory and the basic ideas of probability theory, but for the most part, the book is self-contained. Therefore, with its worked examples, plentiful exercises, and topics of direct use to researchers in many disciplines, Generalized Linear Models serves as ideal text, self-study guide, and reference.},
	language = {English},
	publisher = {Chapman and Hall/CRC},
	author = {McCullagh, P. and Nelder, John A.},
	year = {2018},
}

@book{gelman_bayesian_2013,
	edition = {3},
	title = {Bayesian {Data} {Analysis}},
	publisher = {Chapman \& Hall/CRC},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
	year = {2013},
}

@book{hosmer_applied_2013,
	edition = {3},
	title = {Applied {Logistic} {Regression}},
	publisher = {Wiley},
	author = {Hosmer, David W. and Lemeshow, Stanley and Sturdivant, Rodney X.},
	month = mar,
	year = {2013},
}

@book{johnson_univariate_2005,
	edition = {3},
	title = {Univariate {Discrete} {Distributions}},
	isbn = {978-0-471-27246-5},
	url = {https://onlinelibrary.wiley.com/doi/book/10.1002/0471715816},
	publisher = {Wiley},
	author = {Johnson, Norman L. and Kemp, Adrienne W. and Kotz, Samuel},
	month = jan,
	year = {2005},
}

@book{casella_statistical_2002,
	edition = {2},
	title = {Statistical {Inference}},
	publisher = {Duxbury Advanced Series},
	author = {Casella, George and Berger, L., Roger},
	year = {2002},
}

@article{agresti_approximate_1998,
	title = {Approximate is {Better} than “{Exact}” for {Interval} {Estimation} of {Binomial} {Proportions}},
	volume = {52},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.1998.10480550},
	doi = {10.1080/00031305.1998.10480550},
	abstract = {For interval estimation of a proportion, coverage probabilities tend to be too large for “exact” confidence intervals based on inverting the binomial test and too small for the interval based on inverting the Wald large-sample normal test (i.e., sample proportion ± z-score × estimated standard error). Wilson's suggestion of inverting the related score test with null rather than estimated standard error yields coverage probabilities close to nominal confidence levels, even for very small sample sizes. The 95\% score interval has similar behavior as the adjusted Wald interval obtained after adding two “successes” and two “failures” to the sample. In elementary courses, with the score and adjusted Wald methods it is unnecessary to provide students with awkward sample size guidelines.},
	number = {2},
	urldate = {2025-09-14},
	journal = {The American Statistician},
	author = {Agresti, Alan and Coull, Brent A.},
	month = may,
	year = {1998},
	note = {Publisher: ASA Website
\_eprint: https://doi.org/10.1080/00031305.1998.10480550},
	keywords = {Score test, Confidence interval, Discrete distribution, Exact inference, Poisson distribution, Small sample},
	pages = {119--126},
}

@article{wu_using_2020,
	title = {Using three statistical methods to analyze the association between exposure to 9 compounds and obesity in children and adolescents: {NHANES} 2005-2010},
	volume = {19},
	issn = {1476-069X},
	shorttitle = {Using three statistical methods to analyze the association between exposure to 9 compounds and obesity in children and adolescents},
	url = {https://doi.org/10.1186/s12940-020-00642-6},
	doi = {10.1186/s12940-020-00642-6},
	abstract = {Various risk factors influence obesity differently, and environmental endocrine disruption may increase the occurrence of obesity. However, most of the previous studies have considered only a unitary exposure or a set of similar exposures instead of mixed exposures, which entail complicated interactions. We utilized three statistical models to evaluate the correlations between mixed chemicals to analyze the association between 9 different chemical exposures and obesity in children and adolescents.},
	number = {1},
	urldate = {2025-09-15},
	journal = {Environmental Health},
	author = {Wu, Bangsheng and Jiang, Yi and Jin, Xiaoqing and He, Li},
	month = aug,
	year = {2020},
	keywords = {Adolescent, Bayesian kernel machine regression (BKMR), Child, Obesity, Weighted quantile sum (WQS) regression},
	pages = {94},
	file = {Full Text PDF:C\:\\Users\\samagonz\\Zotero\\storage\\93JAKXPD\\wu2020_using_three_statistical_methods_to_analyze_the_association_between_exposure_to_9_compounds_and_obesi.pdf:application/pdf;Snapshot:C\:\\Users\\samagonz\\Zotero\\storage\\UCE36KX7\\s12940-020-00642-6.html:text/html},
}


@article{branson_randomization-based_2019,
	title = {Randomization-based inference for {Bernoulli} trial experiments and implications for observational studies},
	volume = {28},
	issn = {0962-2802},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6027661/},
	doi = {10.1177/0962280218756689},
	abstract = {We present a randomization-based inferential framework for experiments characterized by a strongly ignorable assignment mechanism where units have independent probabilities of receiving treatment. Previous works on randomization tests often assume these probabilities are equal within blocks of units. We consider the general case where they differ across units and show how to perform randomization tests and obtain point estimates and confidence intervals. Furthermore, we develop rejection-sampling and importance-sampling approaches for conducting randomization-based inference conditional on any statistic of interest, such as the number of treated units or forms of covariate balance. We establish that our randomization tests are valid tests, and through simulation we demonstrate how the rejection-sampling and importance-sampling approaches can yield powerful randomization tests and thus precise inference. Our work also has implications for observational studies, which commonly assume a strongly ignorable assignment mechanism. Most methodologies for observational studies make additional modeling or asymptotic assumptions, while our framework only assumes the strongly ignorable assignment mechanism, and thus can be considered a minimal-assumption approach.},
	number = {5},
	urldate = {2025-09-15},
	journal = {Statistical methods in medical research},
	author = {Branson, Zach and Bind, Marie-Abèle},
	month = may,
	year = {2019},
	pmid = {29451089},
	pmcid = {PMC6027661},
	pages = {1378--1398},
	file = {PubMed Central Full Text PDF:C\:\\Users\\samagonz\\Zotero\\storage\\I3ABLUJF\\branson and bind2019_randomization-based_inference_for_bernoulli_trial_experiments_and_implications_for_observational_stu.pdf:application/pdf},
}

@article{agegnehu_exploring_2021,
	title = {Exploring spatial variation in {BCG} vaccination among children 0–35 months in {Ethiopia}: spatial analysis of {Ethiopian} {Demographic} and {Health} {Survey} 2016},
	volume = {11},
	issn = {2044-6055},
	shorttitle = {Exploring spatial variation in {BCG} vaccination among children 0–35 months in {Ethiopia}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8094339/},
	doi = {10.1136/bmjopen-2020-043565},
	abstract = {Objective
Tuberculosis is a major public health problem and is the second leading cause of death worldwide. BCG vaccination is a life-saving and important part of standard tuberculosis control measures, particularly in Ethiopia where tuberculosis is endemic. The End Tuberculosis Strategy targets of 2020 have not been achieved. Exploring spatial variations in BCG vaccination among children is vital to designing and monitoring effective intervention programmes. Therefore, this study aimed to explore the spatial variation in BCG vaccination among children in Ethiopia.

Design
Cross-sectional study design.

Setting
Ethiopia.

Participants
Children aged 0–35 months.

Primary outcome
BCG vaccination coverage.

Methods
Data from the 2016 Ethiopian Demographic and Health Survey were used and a total of 4453 children aged 0–35 months were included. Spatial autocorrelation analysis, cluster and outlier analysis, hotspot analysis, spatial interpolation, and spatial scan statistics were carried out to identify geographical risk areas for BCG vaccine utilisation. ArcGIS V.10.6 and SaTScan V.9.6 statistical software were employed to explore spatial pattern and significant hotspot areas for BCG vaccination among children.

Results
BCG vaccination was spatially clustered in Ethiopia at the regional level (Global Moran’s I=0.516, p{\textless}0.001). A total of 51 most likely clusters of low BCG vaccination were identified in the Somali and Afar regions (log-likelihood ratio=136.58, p{\textless}0.001). Significant secondary clusters were also identified in North West Gambela, South Amhara, South West Addis Ababa, North East Southern Nations, Nationalities, and People’s Region, and South West Oromia.

Conclusion
A low probability of receiving BCG vaccination was found among children in the Somali and Afar regions. Therefore, these areas should be given attention when designing effective immunisation strategies to improve BCG vaccination among children in order to reduce the burden of tuberculosis in Ethiopia.},
	number = {4},
	urldate = {2025-09-15},
	journal = {BMJ Open},
	author = {Agegnehu, Chilot Desta and Alem, Adugnaw Zeleke},
	month = apr,
	year = {2021},
	pmid = {33910946},
	pmcid = {PMC8094339},
	pages = {e043565},
	file = {PubMed Central Full Text PDF:C\:\\Users\\samagonz\\Zotero\\storage\\N568DTZR\\agegnehu and alem2021_exploring_spatial_variation_in_bcg_vaccination_among_children_0–35_months_in_ethiopia_spatial_analy.pdf:application/pdf},
}

@article{abbasi_partial_2022,
	title = {On partial randomized response model using ranked set sampling},
	volume = {17},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9707803/},
	doi = {10.1371/journal.pone.0277497},
	abstract = {In this paper, we propose a partial randomized response technique to collect reliable sensitive data for estimation of population proportion in ranked set sampling (RSS) scheme using auxiliary information. The idea is to increase confidence and (or) co-operation of the respondents by providing them the option of both ‘direct’ and ‘randomized’ response for the inquired sensitive question. This option is quite logical because perception of sensitive (insensitive) inquiry can vary among respondents. The properties of the proposed method are discussed and compared with existing randomized response techniques. Cost analysis is also carried out to prove supremacy of the suggested method. Finally, an application to clinical trial on AIDS is included.},
	number = {11},
	urldate = {2025-09-15},
	journal = {PLOS ONE},
	author = {Abbasi, Azhar Mehmood and Shad, Muhammad Yousaf and Ahmed, Aneel},
	month = nov,
	year = {2022},
	pmid = {36445862},
	pmcid = {PMC9707803},
	pages = {e0277497},
	file = {PubMed Central Full Text PDF:C\:\\Users\\samagonz\\Zotero\\storage\\F3Z8WMDW\\abbasi2022_on_partial_randomized_response_model_using_ranked_set_sampling.pdf:application/pdf},
}

@article{balanTutorialFrailtyModels2020,
  title = {A Tutorial on Frailty Models},
  author = {Balan, Theodor A and Putter, Hein},
  year = 2020,
  month = nov,
  journal = {Statistical Methods in Medical Research},
  volume = {29},
  number = {11},
  pages = {3424--3454},
  issn = {0962-2802},
  doi = {10.1177/0962280220921889},
  urldate = {2025-11-02},
  abstract = {The hazard function plays a central role in survival analysis. In a homogeneous population, the distribution of the time to event, described by the hazard, is the same for each individual. Heterogeneity in the distributions can be accounted for by including covariates in a model for the hazard, for instance a proportional hazards model. In this model, individuals with the same value of the covariates will have the same distribution. It is natural to think that not all covariates that are thought to influence the distribution of the survival outcome are included in the model. This implies that there is unobserved heterogeneity; individuals with the same value of the covariates may have different distributions. One way of accounting for this unobserved heterogeneity is to include random effects in the model. In the context of hazard models for time to event outcomes, such random effects are called frailties, and the resulting models are called frailty models. In this tutorial, we study frailty models for survival outcomes. We illustrate how frailties induce selection of healthier individuals among survivors, and show how shared frailties can be used to model positively dependent survival outcomes in clustered data. The Laplace transform of the frailty distribution plays a central role in relating the hazards, conditional on the frailty, to hazards and survival functions observed in a population. Available software, mainly in R, will be discussed, and the use of frailty models is illustrated in two different applications, one on center effects and the other on recurrent events.},
  pmcid = {PMC7534210},
  pmid = {32466712},
  file = {C:\Users\sbelg\Zotero\storage\EQTES5NU\balan and putter2020_a_tutorial_on_frailty_models.pdf}
}

@article{hafemeisterNormalizationVarianceStabilization2019,
  title = {Normalization and Variance Stabilization of Single-Cell {{RNA-seq}} Data Using Regularized Negative Binomial Regression},
  author = {Hafemeister, Christoph and Satija, Rahul},
  year = 2019,
  month = dec,
  journal = {Genome Biology},
  volume = {20},
  number = {1},
  pages = {296},
  issn = {1474-760X},
  doi = {10.1186/s13059-019-1874-1},
  urldate = {2025-11-02},
  abstract = {Single-cell RNA-seq (scRNA-seq) data exhibits significant cell-to-cell variation due to technical factors, including the number of molecules detected in each cell, which can confound biological heterogeneity with technical effects. To address this, we present a modeling framework for the normalization and variance stabilization of molecular count data from scRNA-seq experiments. We propose that the Pearson residuals from ``regularized negative binomial regression,'' where cellular sequencing depth is utilized as a covariate in a generalized linear model, successfully remove the influence of technical characteristics from downstream analyses while preserving biological heterogeneity. Importantly, we show that an unconstrained negative binomial model may overfit scRNA-seq data, and overcome this by pooling information across genes with similar abundances to obtain stable parameter estimates. Our procedure omits the need for heuristic steps including pseudocount addition or log-transformation and improves common downstream analytical tasks such as variable gene selection, dimensional reduction, and differential expression. Our approach can be applied to any UMI-based scRNA-seq dataset and is freely available as part of the R package sctransform, with a direct interface to our single-cell toolkit Seurat.},
  keywords = {Normalization,Single-cell RNA-seq},
  file = {C\:\\Users\\sbelg\\Zotero\\storage\\TXSXJN3X\\hafemeister and satija2019_normalization_and_variance_stabilization_of_single-cell_rna-seq_data_using_regularized_negative_bino.pdf;C\:\\Users\\sbelg\\Zotero\\storage\\UWK4WK6Q\\s13059-019-1874-1.html}
}

@article{lloydRealisticDistributionsInfectious2001,
  title = {Realistic {{Distributions}} of {{Infectious Periods}} in {{Epidemic Models}}: {{Changing Patterns}} of {{Persistence}} and {{Dynamics}}},
  shorttitle = {Realistic {{Distributions}} of {{Infectious Periods}} in {{Epidemic Models}}},
  author = {Lloyd, Alun L.},
  year = 2001,
  month = aug,
  journal = {Theoretical Population Biology},
  volume = {60},
  number = {1},
  pages = {59--71},
  issn = {0040-5809},
  doi = {10.1006/tpbi.2001.1525},
  urldate = {2025-11-02},
  abstract = {Most mathematical models used to study the epidemiology of childhood viral diseases, such as measles, describe the period of infectiousness by an exponential distribution. The effects of including more realistic descriptions of the infectious period within SIR (susceptible/infectious/recovered) models are studied. Less dispersed distributions are seen to have two important epidemiological consequences. First, less stable behaviour is seen within the model: incidence patterns become more complex. Second, disease persistence is diminished: in models with a finite population, the minimum population size needed to allow disease persistence increases. The assumption made concerning the infectious period distribution is of a kind routinely made in the formulation of mathematical models in population biology. Since it has a major effect on the central issues of population persistence and dynamics, the results of this study have broad implications for mathematical modellers of a wide range of biological systems.},
  file = {C\:\\Users\\sbelg\\Zotero\\storage\\YYU39X3E\\lloyd2001_realistic_distributions_of_infectious_periods_in_epidemic_models_changing_patterns_of_persistence_a.pdf;C\:\\Users\\sbelg\\Zotero\\storage\\WE4QR3JY\\S0040580901915254.html}
}

@article{wangGeneExpressionDistribution2018,
  title = {Gene Expression Distribution Deconvolution in Single-Cell {{RNA}} Sequencing},
  author = {Wang, Jingshu and Huang, Mo and Torre, Eduardo and Dueck, Hannah and Shaffer, Sydney and Murray, John and Raj, Arjun and Li, Mingyao and Zhang, Nancy R.},
  year = 2018,
  month = jul,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {28},
  pages = {E6437-E6446},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1721085115},
  urldate = {2025-11-02},
  abstract = {Single-cell RNA sequencing (scRNA-seq) enables the quantification of each gene's expression distribution across cells, thus allowing the assessment of the dispersion, nonzero fraction, and other aspects of its distribution beyond the mean. These statistical characterizations of the gene expression distribution are critical for understanding expression variation and for selecting marker genes for population heterogeneity. However, scRNA-seq data are noisy, with each cell typically sequenced at low coverage, thus making it difficult to infer properties of the gene expression distribution from raw counts. Based on a reexamination of nine public datasets, we propose a simple technical noise model for scRNA-seq data with unique molecular identifiers (UMI). We develop deconvolution of single-cell expression distribution (DESCEND), a method that deconvolves the true cross-cell gene expression distribution from observed scRNA-seq counts, leading to improved estimates of properties of the distribution such as dispersion and nonzero fraction. DESCEND can adjust for cell-level covariates such as cell size, cell cycle, and batch effects. DESCEND's noise model and estimation accuracy are further evaluated through comparisons to RNA FISH data, through data splitting and simulations and through its effectiveness in removing known batch effects. We demonstrate how DESCEND can clarify and improve downstream analyses such as finding differentially expressed genes, identifying cell types, and selecting differentiation markers.},
  file = {C:\Users\sbelg\Zotero\storage\WHB5945F\wang2018_gene_expression_distribution_deconvolution_in_single-cell_rna_sequencing.pdf}
}

@article{wearingAppropriateModelsManagement2005,
  title = {Appropriate {{Models}} for the {{Management}} of {{Infectious Diseases}}},
  author = {Wearing, Helen J and Rohani, Pejman and Keeling, Matt J},
  year = 2005,
  month = jul,
  journal = {PLoS Medicine},
  volume = {2},
  number = {7},
  pages = {e174},
  issn = {1549-1277},
  doi = {10.1371/journal.pmed.0020174},
  urldate = {2025-11-02},
  abstract = {Two current biases in infectious disease models may substantially affect their usefulness in predicting disease oubreaks.},
  pmcid = {PMC1181873},
  pmid = {16013892},
  file = {C:\Users\sbelg\Zotero\storage\CJYXWV4L\wearing2005_appropriate_models_for_the_management_of_infectious_diseases.pdf}
}

@book{feller1968,
  author    = {Feller, William},
  title     = {An Introduction to Probability Theory and Its Applications},
  volume    = {I},
  year      = {1968},
  publisher = {Wiley},
  address   = {New York}
}

@book{lawless1982,
  author    = {Lawless, Jerald F.},
  title     = {Statistical Models and Methods for Lifetime Data},
  year      = {1982},
  publisher = {Wiley},
  address   = {New York}
}

@book{ross2014,
  author    = {Ross, Sheldon M.},
  title     = {Introduction to Probability Models},
  edition   = {11},
  year      = {2014},
  publisher = {Academic Press},
  address   = {London}
}

@book{kleinbaum2012,
  author    = {Kleinbaum, David G. and Klein, Mitchel},
  title     = {Survival Analysis: A Self-Learning Text},
  edition   = {3},
  year      = {2012},
  publisher = {Springer},
  address   = {New York}
}

@misc{odom2024,
  author       = {Odom, Gabriel J.},
  title        = {Formal Foundations of Biostatistical Distributions},
  year         = {2024},
  institution  = {Florida International University},
  note         = {Course materials, PHC 6099: R Computing for Health Data Science}
}

@misc{cdc2020,
  author       = {{Centers for Disease Control and Prevention (CDC)}},
  title        = {Principles of Epidemiology in Public Health Practice},
  edition      = {3},
  year         = {2020},
  address      = {Atlanta, GA},
  publisher    = {U.S. Department of Health and Human Services}
}

